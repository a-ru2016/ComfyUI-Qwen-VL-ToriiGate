{
    "Qwen2.5-VL-3B-Instruct": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-3B-Instruct",
            "modelscope": "qwen/Qwen2.5-VL-3B-Instruct"
        },
        "required_files": [
            "chat_template.json", "merges.txt","model.safetensors.index.json",
            "preprocessor_config.json", "tokenizer.json", "vocab.json",
            "config.json","generation_config.json","tokenizer_config.json",
            "model-00001-of-00002.safetensors",
            "model-00002-of-00002.safetensors"
        ],
        "test_file": "model-00002-of-00002.safetensors",
        "default": true,
        "quantized": false,
        "vram_requirement": {
            "full": 6.0,
            "8bit": 3.5,
            "4bit": 2.0
        }
    },
    "Qwen2.5-VL-3B-Instruct-AWQ": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-3B-Instruct-AWQ",
            "modelscope": "qwen/Qwen2.5-VL-3B-Instruct-AWQ"
        },
        "required_files": [
            "added_tokens.json", "chat_template.json", "merges.txt",
            "preprocessor_config.json", "tokenizer_config.json",
            "tokenizer.json", "vocab.json", "config.json",
            "generation_config.json", "special_tokens_map.json",
            "model.safetensors"
        ],
        "test_file": "model.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 3.0,
            "8bit": 3.0,
            "4bit": 3.0
        }
    },
    "Qwen2.5-VL-7B-Instruct": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-7B-Instruct",
            "modelscope": "qwen/Qwen2.5-VL-7B-Instruct"
        },
        "required_files": [
            "model-00001-of-00005.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00005.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 14.0,
            "8bit": 7.5,
            "4bit": 4.0
        }
    },
    "Qwen2.5-VL-7B-Instruct-AWQ": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-7B-Instruct-AWQ",
            "modelscope": "qwen/Qwen2.5-VL-7B-Instruct-AWQ"
        },
        "required_files": [
            "model-00001-of-00002.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00002.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 7.0,
            "8bit": 7.0,
            "4bit": 7.0
        }
    },
    "Qwen2.5-VL-32B-Instruct": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-32B-Instruct",
            "modelscope": "qwen/Qwen2.5-VL-32B-Instruct"
        },
        "required_files": [
            "model-00001-of-00018.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00018.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 64.0,
            "8bit": 32.5,
            "4bit": 16.5
        }
    },
    "Qwen2.5-VL-32B-Instruct-AWQ": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-32B-Instruct-AWQ",
            "modelscope": "qwen/Qwen2.5-VL-32B-Instruct-AWQ"
        },
        "required_files": [
            "model-00001-of-00006.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00006.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 16.0,
            "8bit": 16.0,
            "4bit": 16.0
        }
    },
    "Qwen2.5-VL-72B-Instruct": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-72B-Instruct",
            "modelscope": "qwen/Qwen2.5-VL-72B-Instruct"
        },
        "required_files": [
            "model-00001-of-00038.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00038.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 144.0,
            "8bit": 72.5,
            "4bit": 36.5
        }
    },
    "Qwen2.5-VL-72B-Instruct-AWQ": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2.5-VL-72B-Instruct-AWQ",
            "modelscope": "qwen/Qwen2.5-VL-72B-Instruct-AWQ"
        },
        "required_files": [
            "model-00001-of-00011.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00011.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 36.0,
            "8bit": 36.0,
            "4bit": 36.0
        }
    },
    "Qwen2-VL-2B": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-2B",
            "modelscope": "qwen/Qwen2-VL-2B"
        },
        "required_files": [
            "model-00001-of-00002.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00002.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 4.0,
            "8bit": 2.5,
            "4bit": 1.5
        }
    },
    "Qwen2-VL-2B-Instruct": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-2B-Instruct",
            "modelscope": "qwen/Qwen2-VL-2B-Instruct"
        },
        "required_files": [
            "model-00001-of-00002.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00002.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 4.0,
            "8bit": 2.5,
            "4bit": 1.5
        }
    },
    "Qwen2-VL-7B-Instruct": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-7B-Instruct",
            "modelscope": "qwen/Qwen2-VL-7B-Instruct"
        },
        "required_files": [
            "model-00001-of-00005.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00005.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 14.0,
            "8bit": 7.5,
            "4bit": 4.0
        }
    },
    "Qwen2-VL-72B-Instruct": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-72B-Instruct",
            "modelscope": "qwen/Qwen2-VL-72B-Instruct"
        },
        "required_files": [
            "model-00001-of-00038.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00038.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 144.0,
            "8bit": 72.5,
            "4bit": 36.5
        }
    },
    "Qwen2-VL-2B-Instruct-AWQ": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-2B-Instruct-AWQ",
            "modelscope": "qwen/Qwen2-VL-2B-Instruct-AWQ"
        },
        "required_files": [
            "model.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json"
        ],
        "test_file": "model.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 2.0,
            "8bit": 2.0,
            "4bit": 2.0
        }
    },
    "Qwen2-VL-2B-Instruct-GPTQ-Int4": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-2B-Instruct-GPTQ-Int4",
            "modelscope": "qwen/Qwen2-VL-2B-Instruct-GPTQ-Int4"
        },
        "required_files": [
            "model.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json"
        ],
        "test_file": "model.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 1.5,
            "8bit": 1.5,
            "4bit": 1.5
        }
    },
    "Qwen2-VL-2B-Instruct-GPTQ-Int8": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-2B-Instruct-GPTQ-Int8",
            "modelscope": "qwen/Qwen2-VL-2B-Instruct-GPTQ-Int8"
        },
        "required_files": [
            "model.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json"
        ],
        "test_file": "model.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 2.5,
            "8bit": 2.5,
            "4bit": 2.5
        }
    },
    "Qwen2-VL-7B-Instruct-AWQ": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-7B-Instruct-AWQ",
            "modelscope": "qwen/Qwen2-VL-7B-Instruct-AWQ"
        },
        "required_files": [
            "model-00001-of-00002.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00002.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 7.0,
            "8bit": 7.0,
            "4bit": 7.0
        }
    },
    "Qwen2-VL-7B-Instruct-GPTQ-Int4": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-7B-Instruct-GPTQ-Int4",
            "modelscope": "qwen/Qwen2-VL-7B-Instruct-GPTQ-Int4"
        },
        "required_files": [
            "model-00001-of-00002.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00002.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 4.0,
            "8bit": 4.0,
            "4bit": 4.0
        }
    },
    "Qwen2-VL-7B-Instruct-GPTQ-Int8": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-7B-Instruct-GPTQ-Int8",
            "modelscope": "qwen/Qwen2-VL-7B-Instruct-GPTQ-Int8"
        },
        "required_files": [
            "model-00001-of-00003.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00003.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 7.5,
            "8bit": 7.5,
            "4bit": 7.5
        }
    },
    "Qwen2-VL-72B-Instruct-AWQ": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-72B-Instruct-AWQ",
            "modelscope": "qwen/Qwen2-VL-72B-Instruct-AWQ"
        },
        "required_files": [
            "model-00001-of-00011.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00011.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 36.0,
            "8bit": 36.0,
            "4bit": 36.0
        }
    },
    "Qwen2-VL-72B-Instruct-GPTQ-Int4": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-72B-Instruct-GPTQ-Int4",
            "modelscope": "qwen/Qwen2-VL-72B-Instruct-GPTQ-Int4"
        },
        "required_files": [
            "model-00001-of-00011.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00011.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 36.0,
            "8bit": 36.0,
            "4bit": 36.0
        }
    },
    "Qwen2-VL-72B-Instruct-GPTQ-Int8": {
        "repo_id": {
            "huggingface": "Qwen/Qwen2-VL-72B-Instruct-GPTQ-Int8",
            "modelscope": "qwen/Qwen2-VL-72B-Instruct-GPTQ-Int8"
        },
        "required_files": [
            "model-00001-of-00021.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00021.safetensors",
        "default": false,
        "quantized": true,
        "vram_requirement": {
            "full": 72.5,
            "8bit": 72.5,
            "4bit": 72.5
        }
    },
    "Qwen2.5-VL-7B-Instruct-abliterated": {
        "repo_id": {
            "huggingface": "huihui-ai/Qwen2.5-VL-7B-Instruct-abliterated",
            "modelscope": "huihui-ai/Qwen2.5-VL-7B-Instruct-abliterated"
        },
        "required_files": [
            "model-00001-of-00004.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00004.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 14.0,
            "8bit": 7.5,
            "4bit": 4.0
        }
    },
    "Minthy/ToriiGate-v0.4-7B": {
        "repo_id": {
            "huggingface": "Minthy/ToriiGate-v0.4-7B",
            "modelscope": "Minthy/ToriiGate-v0.4-7B"
        },
        "required_files": [
            "model-00001-of-00004.safetensors",
            "model-00002-of-00004.safetensors",
            "model-00003-of-00004.safetensors",
            "model-00004-of-00004.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model-00001-of-00004.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 14.0,
            "8bit": 7.5,
            "4bit": 4.0
        }
    },
    "Minthy/ToriiGate-v0.4-2B": {
        "repo_id": {
            "huggingface": "Minthy/ToriiGate-v0.4-2B",
            "modelscope": "Minthy/ToriiGate-v0.4-2B"
        },
        "required_files": [
            "model.safetensors",
            "config.json",
            "tokenizer.json",
            "vocab.json",
            "merges.txt",
            "chat_template.json",
            "preprocessor_config.json",
            "generation_config.json",
            "tokenizer_config.json",
            "model.safetensors.index.json"
        ],
        "test_file": "model.safetensors",
        "default": false,
        "quantized": false,
        "vram_requirement": {
            "full": 4.0,
            "8bit": 2.5,
            "4bit": 1.5
        }
    }
}    